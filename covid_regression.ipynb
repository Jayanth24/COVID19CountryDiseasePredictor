{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "source": [
    "## Dataset Importing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'covid_data.csv'\n",
    "column_names = ['Country (label)', 'Date (label)', 'new_cases', 'new_cases_smoothed', 'new_deaths_smoothed', 'total_cases', 'new_deaths', 'total_deaths', 'new_tests', 'total_tests', 'stringency_index', 'population', 'population_density', 'median_age', 'aged_65_older', 'gdp_per_capita', 'cardiovasc_death_rate', 'diabetes_prevalence', 'human_development_index']\n",
    "\n",
    "raw_dataset = pd.read_csv(url, names=column_names, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_dataset.copy()\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.pop('total_deaths')\n",
    "dataset.pop('new_deaths')\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_by_country = [dataset.where(dataset['Country (label)'] == i) for i in range(1,157)]\n",
    "split_by_country = [split_by_country[i].dropna() for i in range(0,156)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERCENT = .7\n",
    "VALIDATION_PERCENT = .15\n",
    "train_split_index = round(TRAIN_PERCENT * len(split_by_country))\n",
    "valid_split_index = round((TRAIN_PERCENT + VALIDATION_PERCENT) * len(split_by_country))\n",
    "np.random.seed(4)\n",
    "\n",
    "np.random.shuffle(split_by_country)\n",
    "country_train_dataset = split_by_country[0:train_split_index]\n",
    "country_validation_dataset = split_by_country[train_split_index:valid_split_index]\n",
    "country_test_dataset = split_by_country[valid_split_index:len(split_by_country)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.concat(country_train_dataset)\n",
    "validation_dataset = pd.concat(country_validation_dataset)\n",
    "test_dataset = pd.concat(country_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(sorted(train_dataset['Country (label)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(sorted(validation_dataset['Country (label)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(sorted(test_dataset['Country (label)']))"
   ]
  },
  {
   "source": [
    "## Visual Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_covid_deaths(data, country_label):\n",
    "    country_data = data.where(data['Country (label)'] == country_label)\n",
    "    country_data = country_data.dropna()\n",
    "    plt.plot(country_data['Date (label)'], country_data['new_deaths_smoothed'])\n",
    "    plt.xlabel('Days since 4/1/2020')\n",
    "    plt.ylabel('new_deaths_smoothed')\n",
    "    plt.title('Country {}'.format(country_label))\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_covid_deaths(train_dataset,150)"
   ]
  },
  {
   "source": [
    "sns.pairplot(train_dataset[['Date (label)', 'new_cases_smoothed', 'new_deaths_smoothed', 'new_tests']], diag_kind='kde')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_dataset[['new_deaths_smoothed', 'stringency_index', 'population_density', 'gdp_per_capita']], diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "validation_features = validation_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('new_deaths_smoothed')\n",
    "validation_labels = validation_features.pop('new_deaths_smoothed')\n",
    "test_labels = test_features.pop('new_deaths_smoothed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe().transpose()[['mean', 'std']]"
   ]
  },
  {
   "source": [
    "## Normalization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.Normalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer.adapt(np.array(train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = np.array(train_features[:1])\n",
    "\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "  print('First example:', first)\n",
    "  print()\n",
    "  print('Normalized:', normalizer(first).numpy())"
   ]
  },
  {
   "source": [
    "## Linear Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.predict(train_features[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.layers[1].kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = linear_model.fit(\n",
    "    train_features, train_labels, \n",
    "    epochs=100,\n",
    "    # suppress logging\n",
    "    verbose=0,\n",
    "    # Calculate validation results on 20% of the training data\n",
    "    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history, model_str):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.ylim([0, 30])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [new_deaths]')\n",
    "  plt.title('{} Mean Absolute Error'.format(model_str))\n",
    "  plt.legend()\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history, 'Linear Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "\n",
    "test_results['linear_model'] = linear_model.evaluate(\n",
    "    test_features, test_labels, verbose=0)"
   ]
  },
  {
   "source": [
    "## DNN Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(16, activation='elu'),\n",
    "      layers.Dense(16, activation='elu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = build_and_compile_model(normalizer)\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history = dnn_model.fit(\n",
    "    train_features, train_labels,\n",
    "    validation_data=(validation_features, validation_labels),\n",
    "    verbose=0, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history, 'DNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)"
   ]
  },
  {
   "source": [
    "## Performance Analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_results, index=['Mean absolute error [new_deaths]']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_test_predictions = linear_model.predict(test_features).flatten()\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(test_labels, linear_test_predictions)\n",
    "plt.xlabel('True Values [new_deaths]')\n",
    "plt.ylabel('Predictions [new_deaths]')\n",
    "plt.title('Linear Regression True VS Predicted')\n",
    "lims = [0, 500]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_test_predictions = dnn_model.predict(test_features).flatten()\n",
    "\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(test_labels, dnn_test_predictions)\n",
    "plt.xlabel('True Values [new_deaths]')\n",
    "plt.ylabel('Predictions [new_deaths]')\n",
    "plt.title('DNN True VS Predicted')\n",
    "lims = [0, 500]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "_ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = linear_test_predictions - test_labels\n",
    "plt.hist(error, bins=25)\n",
    "plt.xlabel('Prediction Error [new_deaths]')\n",
    "_ = plt.ylabel('Count')\n",
    "plt.title('Linear Regression Prediction Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = dnn_test_predictions - test_labels\n",
    "plt.hist(error, bins=25)\n",
    "plt.xlabel('Prediction Error [new_deaths]')\n",
    "_ = plt.ylabel('Count')\n",
    "plt.title('DNN Prediction Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_covid_deaths_then_plot(model, test_dataset, country_id):\n",
    "    test_dataset = test_dataset.where(test_dataset['Country (label)'] == country_id)\n",
    "    test_dataset = test_dataset.dropna()\n",
    "\n",
    "    test_features = test_dataset.copy()\n",
    "    test_labels = test_features.pop('new_deaths_smoothed')\n",
    "    \n",
    "    test_predictions = model.predict(test_features).flatten()\n",
    "    test_predictions = [round(test_predictions[i]) for i in range(len(test_predictions))]\n",
    "\n",
    "    plt.plot(test_dataset['Date (label)'], test_dataset['new_deaths_smoothed'], label='True Values')\n",
    "    plt.plot(test_dataset['Date (label)'], test_predictions, label='Predicted Values')\n",
    "\n",
    "    plt.xlabel('Days since 4/1/2020')\n",
    "    plt.ylabel('new_deaths_smoothed')\n",
    "    plt.title('Country {}'.format(country_id))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pd.unique(sorted(test_dataset['Country (label)'])):\n",
    "    predicted_covid_deaths_then_plot(linear_model, test_dataset, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pd.unique(sorted(test_dataset['Country (label)'])):\n",
    "    predicted_covid_deaths_then_plot(dnn_model, test_dataset, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}